{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(array_, str_):\n",
    "    bool_ = [array_elt == str_ for array_elt in array_]\n",
    "    return np.flatnonzero(bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    paragraphs = []\n",
    "    for para in doc.paragraphs:\n",
    "        if para.text.strip(' \\n') != '':\n",
    "            paragraphs.append(unicodedata.normalize('NFKD', para.text).strip(' \\n'))\n",
    "    return np.array(paragraphs)\n",
    "\n",
    "document = get_text('Alpha Dentistry vol. 1- Digital Orthodontics INTERNATIONAL (Online Edition).docx')\n",
    "#document_list = list(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some errors I found\n",
    "# normally it is a single word\n",
    "document[index(document, \"8.8 - TROUBLE SHOOTING\")] = \"8.8 - TROUBLESHOOTING\"\n",
    "# it is a question so it should end with '?'\n",
    "document[index(document, 'ALIGNERS, WHAT ARE THOSE')] = 'ALIGNERS, WHAT ARE THOSE?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chapter_from_document(num_chapter, end_paragraph):\n",
    "    chapter = {}\n",
    "    chapter['definitions'] = index(document, f'{num_chapter}.1 - DEFINITIONS')[0]\n",
    "    chapter['expectations'] = index(document, f'{num_chapter}.2 - EXPECTATIONS')[0]\n",
    "    chapter['time'] = index(document, f'{num_chapter}.3 - TIME')[0]\n",
    "    chapter['retention'] = index(document, f'{num_chapter}.4 - RETENTION')[0]\n",
    "    chapter['dental work'] = index(document, f'{num_chapter}.5 - DENTAL WORK')[0]\n",
    "    chapter['comfort/pain'] = index(document, f'{num_chapter}.6 - COMFORT/PAIN')[0]\n",
    "    chapter['money'] = index(document, f'{num_chapter}.7 - MONEY')[0]\n",
    "    chapter['troubleshooting'] = index(document, f'{num_chapter}.8 - TROUBLESHOOTING')[0]\n",
    "    chapter['end'] = index(document, end_paragraph)[0] + 1\n",
    "    return chapter\n",
    "\n",
    "end_paragraphs = ['Now, about smoking, within 17 years plus of experience, I had people smoking with their aligners in. What I can tell you is that their aligners did not stay invisible for long. They turn brownish pretty quickly. Smoking is bad, that you know. Well, I cannot promise this, but I had patients who quit smoking after seeing how quickly the nicotine-stained their aligners. Again, this is a side effect and is not even part of the treatment. I just like to share the story about stains and the life-changing effect on a few individuals.',\n",
    "                  'Smoking will stain aligners and chewing gum sticks to aligners, neither recommended.',\n",
    "                  \"We never recommend smoking, either with or without aligners. If you're a smoker, you already know the causes and the potential harm of smoking. That said, you can smoke with the aligners in place. You may get some tobacco deposit on the aligners but again, you're changing them after 2 weeks. So not a big deal. Chewing gum, on the other hand, you'll learn right away as well. Chewing gum will stick to your aligners and it is pretty hard to get them off. It is not worth it. It can be pretty embarrassing to have to call the dental office and ask for a replacement because you chewed gum and now, you can’t get it off. With the time and fees involved, you'll learn quickly not to chew gum with the aligners in your mouth.\",\n",
    "                  \"You should not be smoking, period. Smoking is not good for you, and it will also stain the plastic of the aligners. About chewing gum, you may end up breaking your aligners. On the other hand, some cases require you to chew on a chewee to help the fitting of your aligners. That will be for your dentist to prescribe if needed. Everything in moderation is good. Don't do something which will take you away from what you're trying to achieve.\",\n",
    "                  \"No. I always say that one great reason for you have aligners therapy is that it is a very good way for you to stop smoking. Having to remove your aligners each time, you will start reducing the number of times your will smoke gradually. That said, if you smoke, you shouldn't wear the aligners while smoking because you will stain them pretty quickly and they won’t be clear and invisible anymore.\",\n",
    "                  \"I don't recommend smoking, not only for the nicotine stain but because it's bad for the tissues and healing. You don't heal when you have nicotine in your body.\",\n",
    "                  \"You can chew gum with them. There's no problem. About smoking, you shouldn’t smoke, period. That’s for your health. That said, if you smoke with your trays on, you might turn them dark and brownish very quickly. That might be an aesthetic problem for the next 2 weeks as you are keeping the same aligners.\",\n",
    "                  \"Smoking, it's the same with the coffee or tea, it will turn the clear aligner yellowish, even brownish. That will go against the invisible treatment goal. About chewing gum, sugarless gum, some of my colleagues will say that chewing gum will help the treatment since you are forcing the teeth inside of the aligners. Personally, I am not advising my patients to chew gums with their aligners.\",\n",
    "                  \"No, you should not smoke, period. You should not smoke or chew gum with your aligner on. Smoking is bad for the health and it will also darken your clear aligners very quickly. Well, chewing gum, you could potentially damage your aligners.\",\n",
    "                  \"In general, I would say to avoid smoking because smoking has been linked to gingivitis and other periodontal problems. Sometimes it is challenging for some patients to keep good oral hygiene while wearing aligners, and the accumulation of plaque will eventually lead to gingivitis. If you combine the two added risks, you are at a higher risk of developing gum disease. I would not recommend smoking, period. In regards to chewing gum, I do not think one is able to chew gum while wearing aligners. You can try, but you will have no satisfaction out of it. Just try and you will see.\",\n",
    "                  ]\n",
    "\n",
    "chapters_idx = []\n",
    "for i in range(1, 10):\n",
    "    chapters_idx.append(get_chapter_from_document(i, end_paragraphs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'definitions': 198,\n",
       "  'expectations': 236,\n",
       "  'time': 284,\n",
       "  'retention': 308,\n",
       "  'dental work': 341,\n",
       "  'comfort/pain': 356,\n",
       "  'money': 376,\n",
       "  'troubleshooting': 391,\n",
       "  'end': 613},\n",
       " {'definitions': 452,\n",
       "  'expectations': 488,\n",
       "  'time': 522,\n",
       "  'retention': 536,\n",
       "  'dental work': 556,\n",
       "  'comfort/pain': 569,\n",
       "  'money': 581,\n",
       "  'troubleshooting': 591,\n",
       "  'end': 787},\n",
       " {'definitions': 638,\n",
       "  'expectations': 676,\n",
       "  'time': 702,\n",
       "  'retention': 716,\n",
       "  'dental work': 731,\n",
       "  'comfort/pain': 743,\n",
       "  'money': 755,\n",
       "  'troubleshooting': 765,\n",
       "  'end': 937},\n",
       " {'definitions': 805,\n",
       "  'expectations': 836,\n",
       "  'time': 859,\n",
       "  'retention': 871,\n",
       "  'dental work': 883,\n",
       "  'comfort/pain': 893,\n",
       "  'money': 905,\n",
       "  'troubleshooting': 915,\n",
       "  'end': 1106},\n",
       " {'definitions': 963,\n",
       "  'expectations': 997,\n",
       "  'time': 1021,\n",
       "  'retention': 1033,\n",
       "  'dental work': 1049,\n",
       "  'comfort/pain': 1062,\n",
       "  'money': 1074,\n",
       "  'troubleshooting': 1084,\n",
       "  'end': 1291},\n",
       " {'definitions': 1132,\n",
       "  'expectations': 1173,\n",
       "  'time': 1198,\n",
       "  'retention': 1210,\n",
       "  'dental work': 1231,\n",
       "  'comfort/pain': 1245,\n",
       "  'money': 1258,\n",
       "  'troubleshooting': 1268,\n",
       "  'end': 1468},\n",
       " {'definitions': 1313,\n",
       "  'expectations': 1352,\n",
       "  'time': 1382,\n",
       "  'retention': 1396,\n",
       "  'dental work': 1410,\n",
       "  'comfort/pain': 1418,\n",
       "  'money': 1430,\n",
       "  'troubleshooting': 1442,\n",
       "  'end': 1640},\n",
       " {'definitions': 1488,\n",
       "  'expectations': 1530,\n",
       "  'time': 1558,\n",
       "  'retention': 1568,\n",
       "  'dental work': 1584,\n",
       "  'comfort/pain': 1596,\n",
       "  'money': 1608,\n",
       "  'troubleshooting': 1618,\n",
       "  'end': 1799},\n",
       " {'definitions': 1665,\n",
       "  'expectations': 1697,\n",
       "  'time': 1719,\n",
       "  'retention': 1729,\n",
       "  'dental work': 1749,\n",
       "  'comfort/pain': 1757,\n",
       "  'money': 1769,\n",
       "  'troubleshooting': 1779,\n",
       "  'end': 1953}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALIGNERS, WHAT ARE THOSE? chapter 1': 'Before, to straighten the teeth, we used brackets and wires. So mainly we installed brackets on your teeth and, with wires with elastic memory, the wire will slowly bend back to its original shape, which is a U shape. The U shape is often the desired shape of the mouth. Since 1997, we now have a better way to straighten teeth without the use of brackets and wire. We now leverage the digitalization of the mouth to straighten the smile, tooth by tooth. It is possible by creating a sequence of clear plastic moulds that will guide the movement of the crooked teeth into their desired positions. Moving from one aligner to the next, we can now successfully reshape the mouth and most smiles without metal brackets or wires. Except for the cases that required orthognathic surgery, most cases today can be addressed with the new digital orthodontics, which the leading brand is Invisalign.',\n",
       " 'WHAT ARE THE ALIGNERS MADE OF? WHAT IS THE MATERIAL? DOES IT CONTAIN BPA? chapter 1': \"To tell you the truth. I don't know the exact composition of the material. Invisalign SmartTrack aligners are made of medical-grade nontoxic and reliable plastic. The exact components are protected by patterns.  Over the last 20 years, they have improved much on the plastic itself, making it smarter and smarter and reactive. What I can tell you, is that it is working and working consistently pretty well.\",\n",
       " 'IS IT SAFE? chapter 1': 'Yes, the clear aligners made by aligned tech are medical grade plastic reliable, safe and FDA approved. Personally, I’ve been creating beautiful smiles and changing lives using this technology for more than 17 years by now, with outstanding and consistent results.',\n",
       " 'IS IT FDA APPROVED? chapter 1': 'Yes, the leading brand in clear orthodontics, Invisalign, is FDA approved and made of medical-grade plastic.',\n",
       " 'HOW MANY PEOPLE HAVE USED IT BEFORE ME? chapter 1': 'Invisalign, as the leading brand, has successfully treated more than 11 million smiles, by the time of this writing, all around the world since 1997.',\n",
       " 'HOW OLD ARE THE COMPANY AND ITS TECHNOLOGY? chapter 1': 'The idea of making sequential moulds to straighten teeth isn’t a new concept. It has its origins as far as the beginning of the 20th century. The technological innovation of the leading brand, Invisalign, is the use of computers and 3D models to plan for the treatments and to print out the trays. The pioneer company Align Tech has been around since 1997.',\n",
       " 'HOW EFFICIENT ARE THE CLEAR ALIGNERS? chapter 1': \"With more than 17 years of experience working with this technology, I can tell you with insurance that most cases that are not working, are often due to a lack of patients compliance, (trays should be worn 20 hours+ a day), orthognathic surgical cases,  and very severe rotations and alignment set aside. Just like in everything, you still need a precise diagnosis and a great attending to plan and supervise the case. But once confirmed possible and under capable hands, the main reason for failure is patients' compliance. To know which cases are treatable with clear aligners, an exam by your attending dentist is required.\",\n",
       " 'HOW DOES IT WORK? HOW DOES IT STRAIGHTEN MY TEETH? chapter 1': \"You start with a 3D scan as a digital impression of your mouth. An older technic is to scan a conventional dental impression. That practice is less and less used since the 3D scan is much more reliable and precise.  From that scan, a 3D model of your mouth is made. The doctors and the dental technicians are moving your digital teeth and reshaping your mouth from that 3D model. So all of the planning happened outside of your mouth, while you are not even there. Placing your teeth one by one and carefully considering the inter-relationship of your teeth through every single phase of treatment, a treatment plan is then generated. The blueprint is called a clincheck, with the leading brand, Invisalign. Then it is custom to meet with the patients and show them the simulated virtual treatment on a computer screen prior to the beginning of the actual treatment. Once approved by all parties, a sequence of clear aligners are then 3D printed and shipped to the attending dentist's office for the beginning of the process.\\nChanging from one aligner to the next (usually worn between 7 to 14 days on average), you are executing the treatment plan, a single mould at a time, moving your teeth from A to B to, eventually Z. The mechanics and biology behind the treatment are the mechanism of bone formation and bone resorption. Under pressure, the body will produce hormones to resorb (destroy) the bone until the pressure is released. After that initial hormonal reaction, your body will then start the bone formation process where it detects tension. Within 2 different phases, the body is remoulding itself around the new teeth position within the aligners. In other words, we are using the tooth as leverage to reshape in 2 steps the bone socket, changing slowly the axis of emergence of the tooth. This is how both conventional braces and the new clear aligners are aligning teeth.\\nThe use of plastic aligners or metal brackets and wires is a decision between the attending and his or her patient. The physiology and mechanics are the same. But the clear aligners still have an edge, which is to apply the maximum force on the teeth without the body responding by an equal and opposite force.  No matter the choice of appliances, the body will need the time to regenerate the bone around the teeth, making a minimum of wearing time mandatory. It is also important to understand that this is a hormonal response. Hormonal responses are all-or-nothing reactions. So either your body is creating bone or either it is destroying it. The cycles will follow one after the next, making it mandatory to give your body enough time to go through both sequences.\",\n",
       " 'MY DOCTOR MENTIONED \"ATTACHMENTS.\" WHAT ARE THEY AND WHY WOULD I NEED THEM FOR MY ORTHODONTIC TREATMENT? chapter 1': 'Please keep in mind that this is an orthodontic process to mould bone and replace metal brackets. To maximize and even sometimes, to make a movement possible, we need maximum control over that tooth. An attachment is like a handle temporarily glued on the tooth to increase the movement and its precision. Without attachment, we are losing part of the precision and force of movement, making the treatment either longer or even inefficient. This is often not an option open for debate. As a general rule, attachments can not only move teeth, but they can also optimize the movement within each aligner, making the whole process quicker than without attachments.\\nWhile in treatment, patients will pull against these attachments and some will fall. Don\\'t beat yourself up for that. If the teeth are still within the \"track\" of the movement, you can still move forward. The impression of that tooth will be addressed during your refinement process, as your mouth will be scanned again for refinement. Attachments are present in most clear aligners treatment plans, especially in hard cases and severe crowding. I like to remove the attachments at the end of the first set of aligners after I have accomplished the biggest dental movements. By then, I would have accomplished 80 to 90% of my results. After that, I prefer to give my patient more comfort and confidence and avoid installing new attachments. It is not always possible, but when it is, it is greatly appreciated by the patient.\\nI do so because I keep in mind that 50% of my success is dental-based. I still need the cooperation of the patient for the other 50%. Where it is possible to give them more freedom and comfort, I will do so, knowing that after the first half of the treatment and when the teeth are about straight, your patient is often less compliant to wear his or her aligners as much. By helping them, I am helping my cause for compliance. With experience, not listening at all to the concern of my patients, I am setting myself up for failure. Compliance and psychology are the main components of modern orthodontics. An attachment is made of composite, the same white filling material used to repair dental cavities. It can be colour-matched to the teeth and can be removed pretty easily without leaving any trace on that tooth once due for removal.',\n",
       " \"WHO CAN HAVE ALIGNERS? HOW DO YOU KNOW IF YOU'RE THE RIGHT CANDIDATE? chapter 1\": 'The only way to know for sure is to consult a certified provider. Once your attending dentist has asserted the case in an initial consultation, you will have answers to your 3 primary questions: Possible or not, how long, and how much?',\n",
       " 'AT WHAT AGE CAN I START WITH ALIGNERS? chapter 1': \"Usually, you want to start aligning your teeth once all the adult teeth have erupted. Usually, that's between 11 and 13 years old. There is no upper limit of age to align your teeth using digital orthodontics. Patients as young as 80 years old have successfully corrected their crowding and gained a new smile. The reason why we are only starting to realign teeth once the adult teeth are present is that digital orthodontics is about moving teeth, not bones. When you hear that you have to catch a malocclusion at a young age, we are talking about bone alignment. That's orthopedic, the movement of bones. That is addressed from the age of 6 and above with orthopedic appliances, appliances influencing and guiding the growth of the bones of your face.\\nOnce puberty is reached and most of the adult teeth are already in the mouth, it is now a matter of managing the space inside the mouth to fit in and align the smile, unless the case required jaw surgery, which is, once more, an orthopedic issue. So, in short answer, you can start aligning your teeth with aligners once your adult teeth are in. There is no such thing that you are too old to align your teeth using this technology, for as long as you are healthy and, of course, you have the see to do so.\",\n",
       " 'WHAT ARE THE DIFFERENCES BETWEEN TRADITIONAL BRACES AND ALIGNERS? chapter 1': 'Exactly what you think! One is in metal and one is in clear plastic. Usually, metal braces for the exact same case will be more affordable. At a younger age, attending doctors will prefer braces to aligners because they keep full control of the case, not relying as much on the cooperation of the patient. Now, they are both efficient, aligners and braces. If you need a comparison, think of a convertible and an S.U.V. The convertible is sexy and very desirable on city streets. In the mountains, you will prefer your 4x4 S.U.V. Well, the aligners are that convertible and the braces are the S.U.V. The city streets and the mountains are the difficulty level of your case. I can never say that enough, each case is unique and the only way to know what is the difficulty level, in other words, the complexity of your case is from a consultation with a qualified doctor.\\nIn North America and Europe, more and more adults are looking to straighten their teeth or to re-straighten their teeth with aligners. In some countries, it is still a symbol of wealth to have braces in the mouth. That is a cultural issue. If not for medical reasons, both are effective treatments if applied to the right cases. Another general rule, parents and attending doctors will prefer braces for children and young teenagers because of compliance issues and, most of the time, because of the cost, braces are usually cheaper than aligners. You can be surprised by how educated our children are. They are making their research on the web. I had kids of 12 years old in front of me defending their case to have aligners instead of braces. Once again, if it is about moving teeth, both alternatives are possible. If it is a bone issue, usually, braces and orthognathic surgery will be the correct answer. Only a qualified dentist can clearly answer that question.',\n",
       " 'HOW DO I  KNOW IF I  QUALIFY FOR ALIGNERS? chapter 1': \"The right and short answer to that one is to consult a qualified dentist or orthodontist. If your case is about moving teeth alone, both aligners and braces can do. If the issue is more about bones and the alignment of your jaw, that's orthopedic and the solutions are jaw surgery and braces. As a general rule, braces are more powerful as a tool. I like to compare them to an S.U.V. versus a convertible. You've guessed right, the aligner is that convertible. The difference is the kind of road you are using them on. Off-road, you want your S.U.V. a.k.a, braces. On city streets, you like the sex appeal of a convertible, a.k.a, aligners. The only way to know what your case is is to consult a qualified doctor.  Unfortunately, looking in the mirror and looking on the internet alone will not be enough to have an idea of your treatment plan or your time of treatment. The best example that comes to my mind, are these cases with only 1 tooth out of place. I've seen so many patients coming in consultation thinking that if we have made magic aligning all the teeth of their friends, aligning 1 single tooth should be a walk in the park. In other words, it should not take too long. Very wrong!\\nHow do you think that I can align your smile if 1 single tooth is out of place? I will have to move all the rest of the teeth you qualify as straight and realign your smile keeping the face symmetry and the function of your mouth. If you look good today, except for a tooth, and you want to look better, well, I will have to change the complete dynamic and balance of your mouth to give you a new balance, one you want to see. In short, your treatment is as long as that friend of yours which I have changed his or her life, only now, in your case, I will have to show you the logic of treatment first. What will determine a time treatment is the teeth movement, not how many teeth are out of place. To a patient with many, many teeth misaligned, the treatment is possible and the moral is often positive. With a patient with only 1 tooth out of place, it might be the same treatment, the same time frame, but now, the moral will be much of a challenge.\",\n",
       " 'WHY DO WE HAVE TO DO CLEANING EVERY 3 MONTHS WHEN WEARING ALIGNERS? chapter 1': \"The answer is straightforward, you do not want any complications while in treatment. It is a matter of health and also one of finance to keep the cost under control. The rule is the same as with braces. We need you to keep your mouth clean to avoid cavities, gum diseases, and any other complications that might slow down or even stall the orthodontics process. The rule of 3 to 4 months is based on the fact that it usually takes 3 to 4 months for calculus and decays to appear in the mouth. If those are prevented and removed before needing treatment, the same aligners custom-made to your teeth can be used to continue your treatment. In the advent that you might need dental work, chances are that your teeth will be repaired and won't match the same custom-made aligners. In that case, you will need a new scan and the production of new custom-made aligners, thus engaging extra fees for both the dental work and the new aligners.\\nHaving your teeth cleaned every 3 to 4 months will still require you to also floss and brush your teeth after each meal. You were supposed to brush your teeth 3 times a day and floss, at least once, before going to bed. Guess what? Now you really have to do so. On top of flossing, if you feel food stuck in between your teeth during the day, you need to clean that too. See it this way, it is much cheaper and faster for your to brush, floss, and see your dentist for a cleaning 3 times a year than to pay for the complications of dental work and custom-made aligners.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_questions_and_answers_from_section(section_idx_start, section_idx_end, chapter_idx):\n",
    "    section = document[section_idx_start:section_idx_end]\n",
    "    questions_bool = np.array([(elt[-1] == '?' and elt.isupper()) for elt in section])\n",
    "    questions_args = np.flatnonzero(questions_bool)\n",
    "    questions = section[questions_args]\n",
    "    for i in range(len(questions)):\n",
    "        questions[i] += \" chapter \" + str(chapter_idx)\n",
    "    answers = ['\\n'.join(section[np.arange(questions_args[i-1]+1, questions_args[i])]) for i in range(1, len(questions_args))]\n",
    "    # answer of the last question\n",
    "    answers.append('\\n'.join(section[np.arange(questions_args[-1]+1, len(section))]))\n",
    "    qst_to_ans = dict(zip(questions, answers))\n",
    "    return qst_to_ans\n",
    "\n",
    "get_questions_and_answers_from_section(chapters_idx[0]['definitions'], chapters_idx[0]['expectations'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions_and_answers_from_document():\n",
    "    sections_names = ['definitions', 'expectations', 'time', 'retention', 'dental work', 'comfort/pain', 'money', 'troubleshooting', 'end']\n",
    "    questions_and_answers = {}\n",
    "    for i in range(1, 11):\n",
    "        chapter_idxs = get_chapter_from_document(i, end_paragraphs[i-1])\n",
    "        for j in range(1, len(sections_names)):\n",
    "            q2a = get_questions_and_answers_from_section(chapter_idxs[sections_names[j-1]], chapter_idxs[sections_names[j]], i)\n",
    "            questions_and_answers.update(q2a)\n",
    "    return questions_and_answers\n",
    "\n",
    "questions_answers_dict = get_questions_and_answers_from_document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([len(elt) for elt in questions_answers_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('HOW EFFICIENT ARE THE CLEAR ALIGNERS? chapter 6', 3958)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(questions_answers_dict.keys())[315], len(list(questions_answers_dict.values())[315])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALIGNERS, WHAT ARE THOSE? chapter 1</th>\n",
       "      <td>Before, to straighten the teeth, we used brack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHAT ARE THE ALIGNERS MADE OF? WHAT IS THE MATERIAL? DOES IT CONTAIN BPA? chapter 1</th>\n",
       "      <td>To tell you the truth. I don't know the exact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS IT SAFE? chapter 1</th>\n",
       "      <td>Yes, the clear aligners made by aligned tech a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS IT FDA APPROVED? chapter 1</th>\n",
       "      <td>Yes, the leading brand in clear orthodontics, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOW MANY PEOPLE HAVE USED IT BEFORE ME? chapter 1</th>\n",
       "      <td>Invisalign, as the leading brand, has successf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              answers\n",
       "ALIGNERS, WHAT ARE THOSE? chapter 1                 Before, to straighten the teeth, we used brack...\n",
       "WHAT ARE THE ALIGNERS MADE OF? WHAT IS THE MATE...  To tell you the truth. I don't know the exact ...\n",
       "IS IT SAFE? chapter 1                               Yes, the clear aligners made by aligned tech a...\n",
       "IS IT FDA APPROVED? chapter 1                       Yes, the leading brand in clear orthodontics, ...\n",
       "HOW MANY PEOPLE HAVE USED IT BEFORE ME? chapter 1   Invisalign, as the leading brand, has successf..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(questions_answers_dict, orient='index', columns=[\"answers\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import time\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=EMBEDDING_MODEL):\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def compute_doc_embeddings(df):\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_embedding(r.answers) for idx, r in df.iterrows()\n",
    "    }\n",
    "\n",
    "def load_embeddings(fname):\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = {}\n",
    "for i in range(0, len(df), 60):\n",
    "    document_embeddings.update(compute_doc_embeddings(df[i:i+60]))\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame.from_dict(document_embeddings, orient='index')\n",
    "df2.to_csv(r'answers_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('answers_embeddings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings_new = dict(zip(df2.index, df2.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x, y):\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query, contexts):\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zarou\\Documents\\GitHub_Projects\\OpenaiAPI\\docx_to_txt.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m order_document_sections_by_query_similarity(\u001b[39m\"\u001b[39;49m\u001b[39mcan I smoke with aligner?\u001b[39;49m\u001b[39m\"\u001b[39;49m, document_embeddings_new)[:\u001b[39m5\u001b[39m]\n",
      "\u001b[1;32mc:\\Users\\zarou\\Documents\\GitHub_Projects\\OpenaiAPI\\docx_to_txt.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39morder_document_sections_by_query_similarity\u001b[39m(query, contexts):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m    to find the most relevant sections. \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m    Return the list of document sections, sorted by relevance in descending order.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     query_embedding \u001b[39m=\u001b[39m get_embedding(query)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     document_similarities \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m([\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         (vector_similarity(query_embedding, doc_embedding), doc_index) \u001b[39mfor\u001b[39;00m doc_index, doc_embedding \u001b[39min\u001b[39;00m contexts\u001b[39m.\u001b[39mitems()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     ], reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m document_similarities\n",
      "\u001b[1;32mc:\\Users\\zarou\\Documents\\GitHub_Projects\\OpenaiAPI\\docx_to_txt.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_embedding\u001b[39m(text, model\u001b[39m=\u001b[39mEMBEDDING_MODEL):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     result \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m       model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m       \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtext\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    624\u001b[0m         ),\n\u001b[0;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    626\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    680\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    681\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    683\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"can I smoke with aligner?\", document_embeddings_new)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context separator contains 3 tokens'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SECTION_LEN = 4000\n",
    "SEPARATOR = \"\\n* \"\n",
    "ENCODING = \"gpt2\"  # encoding for text-davinci-003\n",
    "\n",
    "encoding = tiktoken.get_encoding(ENCODING)\n",
    "separator_len = len(encoding.encode(SEPARATOR))\n",
    "\n",
    "f\"Context separator contains {separator_len} tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.        \n",
    "        document_section = df.loc[section_index]\n",
    "        \n",
    "        chosen_sections_len += len(document_section.answers) + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section.answers.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "            \n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zarou\\Documents\\GitHub_Projects\\OpenaiAPI\\docx_to_txt.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prompt \u001b[39m=\u001b[39m construct_prompt(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mcan I smoke with aligner?\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     document_embeddings_new,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     df\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m===\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, prompt)\n",
      "\u001b[1;32mc:\\Users\\zarou\\Documents\\GitHub_Projects\\OpenaiAPI\\docx_to_txt.ipynb Cell 26\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstruct_prompt\u001b[39m(question: \u001b[39mstr\u001b[39m, context_embeddings: \u001b[39mdict\u001b[39m, df: pd\u001b[39m.\u001b[39mDataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    Fetch relevant \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     most_relevant_document_sections \u001b[39m=\u001b[39m order_document_sections_by_query_similarity(question, context_embeddings)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     chosen_sections \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     chosen_sections_len \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\zarou\\Documents\\GitHub_Projects\\OpenaiAPI\\docx_to_txt.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39morder_document_sections_by_query_similarity\u001b[39m(query, contexts):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m    to find the most relevant sections. \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m    Return the list of document sections, sorted by relevance in descending order.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     query_embedding \u001b[39m=\u001b[39m get_embedding(query)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     document_similarities \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m([\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         (vector_similarity(query_embedding, doc_embedding), doc_index) \u001b[39mfor\u001b[39;00m doc_index, doc_embedding \u001b[39min\u001b[39;00m contexts\u001b[39m.\u001b[39mitems()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     ], reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m document_similarities\n",
      "\u001b[1;32mc:\\Users\\zarou\\Documents\\GitHub_Projects\\OpenaiAPI\\docx_to_txt.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_embedding\u001b[39m(text, model\u001b[39m=\u001b[39mEMBEDDING_MODEL):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     result \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m       model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m       \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtext\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zarou/Documents/GitHub_Projects/OpenaiAPI/docx_to_txt.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    624\u001b[0m         ),\n\u001b[0;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    626\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    680\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    681\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    683\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "prompt = construct_prompt(\n",
    "    \"can I smoke with aligner?\",\n",
    "    document_embeddings_new,\n",
    "    df\n",
    ")\n",
    "\n",
    "print(\"===\\n\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 500,\n",
    "    \"model\": COMPLETIONS_MODEL,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embeddings,\n",
    "    show_prompt: bool = False\n",
    ") -> str:\n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "                prompt=prompt,\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m answer_query_with_context(\u001b[39m\"\u001b[39;49m\u001b[39mWhat is a dental aligner?\u001b[39;49m\u001b[39m\"\u001b[39;49m, df, document_embeddings_new)\n",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m, in \u001b[0;36manswer_query_with_context\u001b[1;34m(query, df, document_embeddings, show_prompt)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manswer_query_with_context\u001b[39m(\n\u001b[0;32m      2\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m      3\u001b[0m     df: pd\u001b[39m.\u001b[39mDataFrame,\n\u001b[0;32m      4\u001b[0m     document_embeddings,\n\u001b[0;32m      5\u001b[0m     show_prompt: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      6\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m----> 7\u001b[0m     prompt \u001b[39m=\u001b[39m construct_prompt(\n\u001b[0;32m      8\u001b[0m         query,\n\u001b[0;32m      9\u001b[0m         document_embeddings,\n\u001b[0;32m     10\u001b[0m         df\n\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m show_prompt:\n\u001b[0;32m     14\u001b[0m         \u001b[39mprint\u001b[39m(prompt)\n",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m, in \u001b[0;36mconstruct_prompt\u001b[1;34m(question, context_embeddings, df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstruct_prompt\u001b[39m(question: \u001b[39mstr\u001b[39m, context_embeddings: \u001b[39mdict\u001b[39m, df: pd\u001b[39m.\u001b[39mDataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    Fetch relevant \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     most_relevant_document_sections \u001b[39m=\u001b[39m order_document_sections_by_query_similarity(question, context_embeddings)\n\u001b[0;32m      7\u001b[0m     chosen_sections \u001b[39m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m     chosen_sections_len \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[19], line 16\u001b[0m, in \u001b[0;36morder_document_sections_by_query_similarity\u001b[1;34m(query, contexts)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39morder_document_sections_by_query_similarity\u001b[39m(query, contexts):\n\u001b[0;32m     10\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m    to find the most relevant sections. \u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m    Return the list of document sections, sorted by relevance in descending order.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     query_embedding \u001b[39m=\u001b[39m get_embedding(query)\n\u001b[0;32m     18\u001b[0m     document_similarities \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m([\n\u001b[0;32m     19\u001b[0m         (vector_similarity(query_embedding, doc_embedding), doc_index) \u001b[39mfor\u001b[39;00m doc_index, doc_embedding \u001b[39min\u001b[39;00m contexts\u001b[39m.\u001b[39mitems()\n\u001b[0;32m     20\u001b[0m     ], reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m document_similarities\n",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(text, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_embedding\u001b[39m(text, model\u001b[39m=\u001b[39mEMBEDDING_MODEL):\n\u001b[1;32m----> 2\u001b[0m     result \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      3\u001b[0m       model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      4\u001b[0m       \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtext\n\u001b[0;32m      5\u001b[0m     )\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[0;32m    141\u001b[0m         timeout,\n\u001b[0;32m    142\u001b[0m         stream,\n\u001b[0;32m    143\u001b[0m         headers,\n\u001b[0;32m    144\u001b[0m         request_timeout,\n\u001b[0;32m    145\u001b[0m         typed_api_type,\n\u001b[0;32m    146\u001b[0m         requestor,\n\u001b[0;32m    147\u001b[0m         url,\n\u001b[0;32m    148\u001b[0m         params,\n\u001b[1;32m--> 149\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__prepare_create_request(\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[0;32m    153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:106\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    104\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[1;32m--> 106\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[0;32m    107\u001b[0m     api_key,\n\u001b[0;32m    108\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[0;32m    109\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[0;32m    110\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[0;32m    111\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    113\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    115\u001b[0m     deployment_id,\n\u001b[0;32m    116\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m     params,\n\u001b[0;32m    125\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_requestor.py:130\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[1;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     organization\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    128\u001b[0m ):\n\u001b[0;32m    129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[1;32m--> 130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[0;32m    131\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[0;32m    132\u001b[0m         ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[0;32m    133\u001b[0m         \u001b[39mif\u001b[39;00m api_type\n\u001b[0;32m    134\u001b[0m         \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_version \u001b[39m=\u001b[39m api_version \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_version\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39mapi_key\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[0;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions."
     ]
    }
   ],
   "source": [
    "answer_query_with_context(\"What is a dental aligner?\", df, document_embeddings_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 8 document sections:\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 3\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 4\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 9\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 10\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 5\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 1\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 2\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No, you should not smoke with aligner.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"can I smoke with aligner?\", df, document_embeddings_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 8 document sections:\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 3\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 2\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 4\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 1\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 9\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 10\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 5\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Smoking will stain aligners.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"what will happen if I smoke with aligners?\", df, document_embeddings_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 8 document sections:\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 3\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 4\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 1\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 9\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 10\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 5\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 2\n",
      "CAN I SMOKE OR CHEW GUM WITH ALIGNERS? chapter 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Smoking with aligners will stain the plastic of the aligners, turning them yellowish or brownish. This will go against the goal of having an invisible treatment. Additionally, smoking has been linked to gingivitis and other periodontal problems, which can be challenging to avoid while wearing aligners.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"what will happen if I smoke with aligners?, please go in details.\", df, document_embeddings_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m answer_query_with_context(\u001b[39m\"\u001b[39;49m\u001b[39mhow much cost aan invisalign treatment\u001b[39;49m\u001b[39m\"\u001b[39;49m, df, document_embeddings_new)\n",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m, in \u001b[0;36manswer_query_with_context\u001b[1;34m(query, df, document_embeddings, show_prompt)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manswer_query_with_context\u001b[39m(\n\u001b[0;32m      2\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m      3\u001b[0m     df: pd\u001b[39m.\u001b[39mDataFrame,\n\u001b[0;32m      4\u001b[0m     document_embeddings,\n\u001b[0;32m      5\u001b[0m     show_prompt: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      6\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m----> 7\u001b[0m     prompt \u001b[39m=\u001b[39m construct_prompt(\n\u001b[0;32m      8\u001b[0m         query,\n\u001b[0;32m      9\u001b[0m         document_embeddings,\n\u001b[0;32m     10\u001b[0m         df\n\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m show_prompt:\n\u001b[0;32m     14\u001b[0m         \u001b[39mprint\u001b[39m(prompt)\n",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m, in \u001b[0;36mconstruct_prompt\u001b[1;34m(question, context_embeddings, df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstruct_prompt\u001b[39m(question: \u001b[39mstr\u001b[39m, context_embeddings: \u001b[39mdict\u001b[39m, df: pd\u001b[39m.\u001b[39mDataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    Fetch relevant \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     most_relevant_document_sections \u001b[39m=\u001b[39m order_document_sections_by_query_similarity(question, context_embeddings)\n\u001b[0;32m      7\u001b[0m     chosen_sections \u001b[39m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m     chosen_sections_len \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[19], line 16\u001b[0m, in \u001b[0;36morder_document_sections_by_query_similarity\u001b[1;34m(query, contexts)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39morder_document_sections_by_query_similarity\u001b[39m(query, contexts):\n\u001b[0;32m     10\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m    to find the most relevant sections. \u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m    Return the list of document sections, sorted by relevance in descending order.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     query_embedding \u001b[39m=\u001b[39m get_embedding(query)\n\u001b[0;32m     18\u001b[0m     document_similarities \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m([\n\u001b[0;32m     19\u001b[0m         (vector_similarity(query_embedding, doc_embedding), doc_index) \u001b[39mfor\u001b[39;00m doc_index, doc_embedding \u001b[39min\u001b[39;00m contexts\u001b[39m.\u001b[39mitems()\n\u001b[0;32m     20\u001b[0m     ], reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m document_similarities\n",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(text, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_embedding\u001b[39m(text, model\u001b[39m=\u001b[39mEMBEDDING_MODEL):\n\u001b[1;32m----> 2\u001b[0m     result \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      3\u001b[0m       model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      4\u001b[0m       \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtext\n\u001b[0;32m      5\u001b[0m     )\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[0;32m    141\u001b[0m         timeout,\n\u001b[0;32m    142\u001b[0m         stream,\n\u001b[0;32m    143\u001b[0m         headers,\n\u001b[0;32m    144\u001b[0m         request_timeout,\n\u001b[0;32m    145\u001b[0m         typed_api_type,\n\u001b[0;32m    146\u001b[0m         requestor,\n\u001b[0;32m    147\u001b[0m         url,\n\u001b[0;32m    148\u001b[0m         params,\n\u001b[1;32m--> 149\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__prepare_create_request(\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[0;32m    153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:106\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    104\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[1;32m--> 106\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[0;32m    107\u001b[0m     api_key,\n\u001b[0;32m    108\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[0;32m    109\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[0;32m    110\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[0;32m    111\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    113\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    115\u001b[0m     deployment_id,\n\u001b[0;32m    116\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m     params,\n\u001b[0;32m    125\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\api_requestor.py:130\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[1;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     organization\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    128\u001b[0m ):\n\u001b[0;32m    129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[1;32m--> 130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[0;32m    131\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[0;32m    132\u001b[0m         ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[0;32m    133\u001b[0m         \u001b[39mif\u001b[39;00m api_type\n\u001b[0;32m    134\u001b[0m         \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_version \u001b[39m=\u001b[39m api_version \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_version\n",
      "File \u001b[1;32mc:\\Users\\zarou\\anaconda3\\envs\\openai_api\\lib\\site-packages\\openai\\util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39mapi_key\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[0;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions."
     ]
    }
   ],
   "source": [
    "answer_query_with_context(\"how much cost aan invisalign treatment\", df, document_embeddings_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
